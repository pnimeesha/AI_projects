{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8f4dea-f94e-4340-bb18-94cd357922f5",
   "metadata": {},
   "source": [
    "# Generate Synthetic Queries with GPT-4o-mini (batch)\n",
    "\n",
    "Based on example from [here](https://sbert.net/docs/sentence_transformer/training_overview.html#trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869ca1f-065f-491e-8949-175c28cfaacb",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c390282b-88ed-46a9-b73c-7fd15404740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "from top_secret import my_sk\n",
    "client = OpenAI(api_key=my_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9a4ee-96f3-44a8-a13c-4fb612c2b9c9",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1b64b0-e760-4090-b294-823dfc1170e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = lambda job_description : f\"\"\"Read the following job description and create a concise job search query with at most 3 specialized skills or \\\n",
    "areas of expertise that are distinct to the role. Exclude generic data science or software engineering skills like AI, machine \\\n",
    "learning, and coding languages unless they are explicitly highlighted as unique or advanced. Keep the query short and human-like, \\\n",
    "suitable for typing into a search engine. \n",
    "\n",
    "Here's the job description: {job_description}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1e1663-cd2f-47d4-9dca-95df458421cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(job_description):\n",
    "    \"\"\"\n",
    "        Function to generate synthetic query to input job description.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate prompt\n",
    "    prompt = prompt_template(job_description)\n",
    "\n",
    "    # make api call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ], \n",
    "        temperature = 0.7\n",
    "    )\n",
    "    \n",
    "    # return response\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd67c0-432b-4ac2-aaea-7ba59023bcbc",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f330c89-ec1f-4acc-b4e6-5276118cc58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123849, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from HF hub\n",
    "ds = load_dataset(\"datastax/linkedin_job_listings\")\n",
    "\n",
    "# convert to pandas df\n",
    "df = ds['train'].to_pandas()\n",
    "\n",
    "# keep only title and description\n",
    "df = df[['title', 'description']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9453fa93-36d8-4325-b9a0-6d55da881b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of strings to search for\n",
    "search_terms = [\"Data Scientist\", \"Data Analyst\", \"Machine Learning Engineer\", \n",
    "                \"Data Engineer\", \"AI Engineer\", \"Deep Learning\"]\n",
    "\n",
    "# Create a regex pattern to match any of the strings\n",
    "pattern = '|'.join(search_terms)\n",
    "\n",
    "# Filter rows that contain any of the search terms\n",
    "df = df[df['title'].str.contains(pattern, case=False, na=False)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de1a73f-605a-4123-8a05-dba4bbb35fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "df.to_csv('data/job_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a60cf-114c-4e1f-9e61-5d696433054f",
   "metadata": {},
   "source": [
    "### Generates queries for JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9402f2-d4fc-4732-b82c-8a0c143e2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description_list = df['description'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e70b7b-70e6-4fd5-9539-a0464b63e954",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # non-batch approach\n",
    "# synthetic_query_list = []\n",
    "# for job_description in job_description_list:\n",
    "#     # generate synthetic query and append to list\n",
    "#     synthetic_query_list.append(generate_query(job_description).replace('\"',''))\n",
    "\n",
    "# # add queries to df\n",
    "# df['query'] = synthetic_query_list\n",
    "\n",
    "# df.to_csv('data/job_data_w_query.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e272d88-6cb4-4608-9a33-93b2cf4e55d4",
   "metadata": {},
   "source": [
    "#### 1) Create batch request file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae01e27-3dd1-4c98-bb6e-15f0ad50c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch requests\n",
    "batch_requests = [\n",
    "    {\n",
    "        \"custom_id\": f\"request-{i+1}\",  # Custom ID for tracking\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt_template(job_description)}\n",
    "            ],\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "    }\n",
    "    for i, job_description in enumerate(job_description_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cb6bab-8e23-4a26-bb73-2e921d551074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to JSONL format (newline-delimited JSON)\n",
    "batch_jsonl = \"\\n\".join(json.dumps(request) for request in batch_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3ad713-1937-4d16-8388-ce684e2484e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save to a .jsonl file\n",
    "with open(\"data/batch_requests.jsonl\", \"w\") as file:\n",
    "    file.write(batch_jsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c77e1-fe5b-4b6f-8c3b-03eaf2b28a64",
   "metadata": {},
   "source": [
    "#### 2) Upload batch request file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a87f0f27-58c4-4282-9dee-190ee8208fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-3vhvpk8unsjMkWe7U8AfP6', bytes=5047825, created_at=1737469194, filename='batch_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "batch_input_file = client.files.create(\n",
    "    file=open(\"data/batch_requests.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9caa218-024a-4cb0-8798-4fbd7a94c475",
   "metadata": {},
   "source": [
    "#### 3) Create batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8330b2-2760-4bd5-9cb1-9b799673cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batch job\n",
    "batch_object = client.batches.create(\n",
    "    input_file_id=batch_input_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"synthetic queries from job descriptions\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72ee51d-7996-4a7b-a9cd-df72d3ca8298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_678fad0c34dc8190990016c0ac76b539', completion_window='24h', created_at=1737469197, endpoint='/v1/chat/completions', input_file_id='file-3vhvpk8unsjMkWe7U8AfP6', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1737555597, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'synthetic queries from job descriptions'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "print(batch_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68204fff-d0d1-4430-b9e3-f0315528d8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
